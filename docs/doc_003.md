### <center><font color=red>刊首语</font></center>

这里记录ML自学者群体，每周分享优秀的学习心得与资料。由于微信不允许外部链接，需要点击文末的「**阅读原文**」，才能访问文中的链接。

---


前几天看到一则新闻，AI界的网红老师Siraj，遭吃瓜群众大规模打假。

Siraj原本是靠在视频网站上传AI教学视频的博主，被称为AI界的最强Rapper，吸粉百万。

当然，他是为了最终能够通过粉丝的支持来进行盈利，这无可厚非。但有件事他做错了，而且是原则性错误。

首先，他的教学代码一般是从Github开源项目复制而来，而且删除了原作者的信息。更过分的事情是，他发表的论文，也是大段不加改动的，从其他论文处复制粘贴，甚至直接截图过来。

![592fbd2e05c77679d5daf66342637f8e.png](https://mmbiz.qpic.cn/mmbiz_png/icmWrEONNM8UlUic5MEQePcibjicaGVlt6ucZLibyic7mWfczA1ez4xT6bicqX4Kmw7Ucy8w6d4ibdKbF8OB8EIwSCfbKw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

于是成了千夫所指，人设一夜崩塌。

这个悲惨的故事，告诉我们，想要成名，还得靠脚踏实地的好好学习。来，看看大家本周都学了什么。

---

### <center><font color=red>本期内容</font></center>

**心得分享**

- 骨骼动作识别模型：AGC-LSTM
- 对FM模型的学习
- 多任务学习概述
- 机器人在对话中推荐物品
- 分水岭分割方法

**学习周记**

- Mr.WR
- 贺
- 君君
- 千禧


**资料分享**

- 超轻量级人脸检测模型
- 中文自然语言处理语料 

---

### <center><font color=red>自学心得</font></center>

#### 骨骼动作识别新模型：AGC-LSTM

本周写了一个软件著作权，并将其邮寄到中国版权保护中心。阅读动作识别综述论文，和再次阅读CVPR论文，

![f54b90d1fe19e01ba63bf293a8699137.png](https://mmbiz.qpic.cn/mmbiz_png/icmWrEONNM8UlUic5MEQePcibjicaGVlt6uceKvicIDzSe1uykyDdajouZzhJsrTR6czNuT5nLGAPz1AVOa9Vgp34dg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

该篇论文首次提出AGC-LSTM网络。不仅能够分别的提取数据在时间和空间上的特征，而且还能查出两者之间的共现联系。在AGC-LSTM顶层，提出了一个时间分层结构，该结构不仅可以提高学习高等级表示的能力，而且还能显著的减少计算代价。

论文名称: An attention enhanced graph convolutional LSTM Network for Skeleton-Based Action Recognition 

[论文地址](https://arxiv.org/pdf/1902.09130.pdf)

#### 对FM模型的学习

![](https://mmbiz.qpic.cn/mmbiz_png/icmWrEONNM8UlUic5MEQePcibjicaGVlt6ucdVkVo26oPnF11Ric6BftWdteHxiclZIzN4AMu662FqxxC5I7CiaVOKQxA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


这周学习FM模型，FM在计算广告和推荐系统中十分常用，主要优点在于考虑了特征交叉，并且算法的时间复杂度仍然还是线行的。

实际业务中，对于离散型的特征经常使用one-hot编码，传统的特征交叉方法使得特征维度扩张较为迅速，而且二阶项的系数很容易训练不充分，而在 FM 中，对于每个特征都学习了一个Embedding二阶项的系数就转化成了特征Embedding之间的内积。

在FM的论文中，比较了SVM和FM之间的优劣和FM与MF的联系，SVM 中的多项式核也可以完成特征交叉，但是并不适合高维稀疏的数据。

MF可以理解为，在评分任务中，把用户对于物品的评分，分解为用户 Embedding 和物品 Embedding 的内积；

FM 的重点在于二阶项的计算方式的改写（改写成线性时间），在这里附上论文和一些其他看过的博客。

论文：
- [FM算法详解](https://blog.csdn.net/bitcarmanlee/article/details/52143909)
- [FM模型理论和实践](https://mp.weixin.qq.com/s?__biz=MzI1MzY0MzE4Mg==&mid=2247483878&idx=1&sn=0a94aff9156bf2902096c77ca2122372&chksm=e9d01127dea79831de1d1d126549cba1996994c210d0be2ae0004b718fd348909b425fe15fe2&mpshare=1&scene=1&srcid=1009NC42Qg2PsMCADYMCjpkv&sharer_sharetime=1570587740133&sharer_shareid=32dc4a57f2d5d60ea8e4e538e6caa1b1%23rd)
- [Factorization Machines](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)
- [推荐系统召回四模型之：全能的FM模型](https://zhuanlan.zhihu.com/p/58160982)
- [前深度学习时代CTR预估模型的演化之路](https://zhuanlan.zhihu.com/p/61154299)

#### 多任务学习概述

![](https://mmbiz.qpic.cn/mmbiz_png/icmWrEONNM8UlUic5MEQePcibjicaGVlt6ucZuicyQccUDcVHicbX5badb6ZaSSykzps7KPJPPwl4AlAib4oiaJuNR0ncA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


今天介绍一下这几天看的一篇多任务概述，发表在arxiv，引用次数393。

多任务学习的直观定义是只要优化多个loss就被称之为多任务学习。为什么关注多任务，是因为我们往往只聚焦于单任务想要优化的目标，但是往往会失去一些关联信息。

从人类学习的角度来讲，在学习复杂任务之前往往会先学习一些简单的任务。从机器学习的视角来看，与主任务相关的辅助任务可以引入一些额外的信息，这些信息被称为inductive bias，我个人理解是引入了一些先验。这些先验会导致模型会更加关注能够解释多个任务的共同部分，而不是只关注解释单单一个任务，这也会使得泛化能力提高。

多任务有效的原因：
1. 同时学习多个任务会平衡在各自任务上的噪声，使得模型能够学到更好的表征；
2. 辅助任务可以引入额外信息。

如何设计辅助任务：作者在这里并没有给出一些方法论，而是给出了一些示例。如目标检测中常常同时输出目标类别和位置，情感分析中有设置预测输入句是否存在正向或负向情感词的辅助任务。

论文名称：An Overview of Multi-Task Learning
in Deep Neural Networks
[论文地址](https://arxiv.org/pdf/1706.05098.pdf)

#### 分水岭分割方法

![](https://mmbiz.qpic.cn/mmbiz_png/icmWrEONNM8UlUic5MEQePcibjicaGVlt6ucXOkkVeoLh44NN9U2iaoxadG3AeK5oHd9LSXcqN2HZ43x0ib5kGLTfQaQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

最近在尝试看论文的代码，不知不觉就研究上了分水岭分割方法。并了解了一下同在scikitimage库中的随机漫步分割方法。在腾讯云上有翻译的中文文档，[地址链接](https://cloud.tencent.com/developer/section/1415081)。

**分水岭算法**：对于没有噪声的图象效果很好。即使是有重叠。
**随机漫步算法**：随机Walker分割基于各向异性扩散的分割算法，通常比分水岭慢，但对噪声数据和孔洞边界具有良好结果。

自己体验下来，感觉分水岭确实是一个很好的传统分割算法，而随机漫步算法进行分割感觉太消耗内存了。在图片没什么噪声的情况下两者相比应该优先选择分水岭

#### 机器人在对话中推荐物品

分享SIGIR2018的一篇文章，个性化的聊天机器人在电商领域，有着可观的前景。目前的多轮对话中，机器人通常仅仅利用到了用户的历史输入信息，忽略了用户长期的偏好，从而给出一些不受欢迎的回复。而推荐系统，能够从用户历史购买的物品或者给出的评分中，学习到更多的用户喜好信息。

这篇文章，将对话和推荐两种看起来有所差异的分支结合到一起，利用深度强化学习框架，建立个性化的对话推荐机器人，从而能够优化对话体验，完成对话目标。这里所说的对话目标，是在电商场景下，成功的推荐商品给用户。

系统主要由三个部分组成：Belief Tracker， Policy Network， Recommender。

![](https://mmbiz.qpic.cn/mmbiz_png/icmWrEONNM8UlUic5MEQePcibjicaGVlt6ucPM321QtyNzC5tfEXjscTOycBiaVdLdTdGMRNGYtFd8G5SDUCcK3RwhQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

论文名称：Conversational Recommender System
[论文地址](https://arxiv.org/abs/1806.03277)

---

### <center><font color=red>学习周记</font></center>

#### Mr.WR

这周把吴恩达的机器学习看完了，麻省理工的stang教授的线代也看完了。机器学习的视频就是入了个门，以后还有很多东西要学，正在最后面的编程练习，感觉好多都看不懂。

接下来这周要好好研究研究，然后同时看Python深度学习这本书和林轩田的机器学习技法，争取在这周看完

#### 贺

这周忙于找工作，没有太多的时间去学习，主要看了一下网易云课堂上厦门大学林子雨老师的大数据原理和应用课程的前十一章，觉得比较适合想要入门大数据以及对大数据有大致的了解的同学，这门免费课程还有配套的教程和相应的资料，确实还不错。

#### 君君

在复现论文过程中，为了生成对应数据集试过的方法之一，虽然最终没有采用该方法生成数据集，不过我觉得这种勇于创新的思路值得记录下来（狗头保命）。

具体背景情况、实验图像、实现代码都详细在下面链接里面有说明，这边就不重复陈述了。[链接地址](https://blog.csdn.net/weixin_43194555/article/details/102535907)

#### 千禧

最近重温了sklearn的调用，从中学习到最新版本的sklearn的细节操作，从案例中积累超参数调整的经验。这里推荐B站视频：[链接地址](https://www.bilibili.com/video/av70627602/?p=27)

---

### <center><font color=red>优质资料</font></center>

#### 超轻量级人脸检测模型


一款超轻量级通用人脸检测模型，模型文件大小仅1MB，320x240输入下计算量仅90MFlops，适用于边缘计算设备、移动端设备以及PC。

[项目地址](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB)

#### 中文自然语言处理语料 

大规模中文自然语言处理语料，包括维基百科，新闻语料，百科问答，社区问答，翻译语料。

[项目地址](https://github.com/brightmart/nlp_chinese_corpus)



---

### 加入我们

公众号内回复「自学」，即可加入ML自学者俱乐部社群。可以投稿每周学习心得或者看到的优质学习资料，助力团体共同学习进步。



---

### 参考来源

- [ML自学者俱乐部投稿](https://github.com/Dikea/ML-SelfStudy-Weekly)
- [黄博的机器学习圈子](https://t.zsxq.com/eaeYv7a)
- [知乎机器学习话题](https://zhihu.com)

[点击阅读上一期内容](https://mp.weixin.qq.com/s/ev3XfCNdM4mE55vTKukyXQ)
